## Variable Types

Data can mean a lot of things, but within data science, it typically means a collection of organized observations. <br />
There are two types of organization: methodology and shape. <br />
The methodology is how the data was collected. <br />
The most common shape for data is a spreadsheet or table. The things we are measuring (variables) are in the columns, and the individual instances (observations) are in the rows. We can read each column “down” the table (viewing multiple observations), and each row “across” the table (viewing multiple variables). <br />
This isn’t the only way to organize data, but it is the most common. <br />

## The Shape of Data

For your new role as a tree census taker, you’ll start with height and species. ‘Height’ and ‘Species’ are our 
variables. The height of each tree can “vary” from one tree to another (hence the name). <br />
Each individual tree is called an entity, observation, or instance (there are a lot of names for this). We’ll stick with observations, but know that these three terms are used interchangeably. <br />
In a well-organized dataset, the variables describe a characteristic of our entities. However, it can be surprisingly difficult to define good variables. Good variables measure only one characteristic and should not be a characteristic themselves.

## Variable Types

In our tree census, we are collecting data about two types of variables: one that we measure (height) and one that we categorize (species). <br />
The difference between measuring and categorizing is so important that the data itself is termed differently:

* Variables that are measured are **Numerical** variables.
* Variables that are categorized are **Categorical** variables.

### Numerical Variables

Numerical variables are a combination of the measurement and the unit. Without the unit, a numerical variable is just a number. <br />
Imagine I go into a cafe and ask the barista for 3. Three what? Coffee? Donuts? Money? Or my friend asks how far Toledo is and I say 300. 300 miles? Kilometers? Minutes? Without units, numbers don’t mean anything. <br />
There are two ways to get a number: by counting and measuring. Counting gives us whole numbers and **discrete** variables. Measuring gives us potentially partial values and **continuous** variables. <br />
In our tree census, we are measuring the height of our trees in feet (indicated in the variable name, ‘Height (ft)’), a continuous variable.

### Categorical Variables

Categorical variables describe characteristics with words or relative values. <br />
In the tree census, trees species are described with words like London Plane, Honeylocust, or Pin Oak. This is the best description and encodes all the information we need about the species. This kind of categorical variable is a **nominal variable** which literally means a named value. <br />
We also captured whether or not our trees grew alone. In our ‘Single’ variable, there were only two options: Yes and No. This is called a **dichotomous variable**. Dichotomous variables have only 2 logical possibilities, “on/off”, “yes/no”, “true/false”, “0/1”, there’s no middle ground and no 3rd option. If there is a logical third option, it’s not a dichotomous variable. <br />
Finally, let’s say that we wanted to capture how “pretty” we thought each tree was. This isn’t really a thing we can measure, but we can subjectively say on a scale of 1 to 5, how pretty we think each tree is. The prettiest trees are a 5, the least pretty trees are a 1. <br />
That ranking is inherently ordered and therefore called an **ordinal variable**. <br />
Ordinal variables are really popular in survey design “on a scale of 1-5 how much do you agree with this statement?” This is called a **likert** scale. They also show up in the Olympics and other competitions where someone wins 1st, 2nd, or 3rd place. <br />
Ordinal variables can get a little confusing because they are often represented as numbers. But they don’t represent measurements or counts, they represent categories. For example, let’s say an Olympian wins Gold and Bronze medals, it doesn’t make sense to say that they averaged Silver. The same is true of likert scales: there’s no average between “Very pretty” and “Pretty.”

## Working with Missing Data

In our dataset, we had some missing values. There are various types of “missing-ness” that affect how we treat the missing data. <br />
When there’s no deeper meaning to why the data is missing like when it just wasn’t entered properly, we refer to this kind of missing as **Missing Completely at Random**. <br />
However, we don’t always know if there is a deeper meaning, so we have to treat missing data like a mystery to solve. For example, we might notice that all of the Redwood trees are missing Height values. Well, that’s interesting! We can predict if a tree is missing its Height value based on what Species it is. <br />
More generally *we can predict if one value is missing based on the value in another variable*. This kind of missing is called **Missing at Random**. It is a confusing label because it’s not really missing at “random” in the normal meaning of the word. If we dig a little deeper into how the data was collected, we might uncover a story about the data collection or about Redwoods. For example, our tape measures might have been too short to measure them. <br />
Finally, data can be structurally missing, meaning that we wouldn’t expect a value there to begin with. For example, let’s say we are also collecting data about fruit on our trees. Some trees will have visible fruit. For those trees, we can count how many fruits are visible. If there’s no visible fruit, we can’t count how many there are. The number of fruits will be **Structurally Missing**.

# Accuracy

Great! We collected our measurements, made decisions about handling missing data. Now we need to ask ourselves if the dataset we have really describes the world. We need to know if it is accurate. Accuracy is a measure of how well records reflect reality. <br />
While doing some Exploratory Data Analysis you notice that the trees you measured are overall taller than the trees I measured. That’s interesting. You’re not really sure why that is, so we compare how we measured the trees. <br />
We realize that you measured starting from the ground and I measured starting from where the roots become the trunk. It’s not a huge difference, but it’s enough to affect the accuracy of our data. The tree heights are not accurate because we don’t know how tall each tree really is. We could also say that the height variable is not *reliable*. Without a standard measurement unit and standard method, comparing trees, or even getting an average tree height is impossible.

# Validity

It’s not just typos, mistakes, missing data, poor measurement, and duplicated observations that make a dataset low quality. We also have to make sure that our data actually measures what we think it is measuring. This is the **validity** of our dataset. <br />
Validity is a special kind of quality measure because it’s not just about the dataset, it’s about the relationship between the dataset and its purpose. A dataset can be valid for one question and invalid for another. <br />
Let’s think again about our trees dataset. After we finished collecting the data, we thought of another question we wanted to answer: how old are our trees? <br />
We know that you can measure the age of a tree by counting the rings, but we didn’t do that. Let’s say that we did measure the width of the tree. <br />
We decide that since number of rings and width are related, we will use width as a proxy for the age. With that decision, we just compromised the **validity** of our dataset. Our data doesn’t measure age, it measures width. And even though there is a relationship between the number of rings and the width, it’s not a direct relationship and therefore cannot be substituted without affecting the validity of our dataset and measures.

# Representative Samples

Great! You’ve cleaned the data, decided what to do about missing data points, resolved any accuracy issues. You’ve made sure that all the questions can be answered by the data we have and gotten all stakeholders to agree on the research questions. <br />
You are ready to do your analysis. Then you notice that all of the records are from New York State. You’ve been hired to work on the census for all of the North Atlantic. That includes multiple states in the U.S. and many regions of Canada. Where is the rest of the data? <br />
You go back to the dataset and start to think about when it was collected. Right, Spring of 2020 - the border was closed. Census takers collected data in the region that they could: the areas that were convenient. This is a **convenience sample**. It’s great for preliminary understanding, but not good for representing a broader population. <br />
If we were to create a model to predict tree prettiness based on the 
variables in our dataset, it might only be relevant for trees in New York. We’ve introduced **bias** into our dataset by constraining our sample. <br />
Convenience samples aren’t the only type of sampling errors, but they are common. The goal of a sample is to represent a population. Any time a sample is made that does NOT reflect the entire population, it is a sampling error. <br />
Best practice is to create a **sample** that represents the entire **population**. <br />
The **population** is all of the trees in the North Atlantic region. The **sample** is the trees that we have data about (it will almost never be all of them). <br />
The sample should look like the population in as many characteristics as possible. Therefore, our sample needs to include many different kinds of trees from many different locations. <br />
There are a lot of techniques for creating representative samples, but they all have the same goal: to find a mix of observations that contains all of the features in the larger population.